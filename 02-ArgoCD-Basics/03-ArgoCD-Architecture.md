# Argo CD: Deep-Dive Architecture & Operational Flows

To manage Kubernetes at scale, Argo CD employs a sophisticated microservices architecture designed for high throughput, security, and eventual consistency.

---

## üèóÔ∏è Core Component Deep-Dive

### 1. API Server (The Gateway)
The API Server is the only external-facing component. It acts as the gateway for the Web UI, CLI, and CI/CD integrations.
*   **Authentication & AuthZ**: It bundles **Dex** for OIDC/SSO and implements a custom Casbin-based **RBAC** engine.
*   **Request Handling**: It manages the `Application` and `AppProject` Custom Resource Definitions (CRDs).
*   **Logic**: When you click "Sync," the API Server creates an `Operation` object on the Application resource, which the Controller then picks up.

### 2. Repository Server (The Generator)
Likely the most resource-intensive component, the Repo Server's job is to turn Git code into YAML.
*   **Manifest Generation**: It shells out to tools like `helm template`, `kustomize build`, or `jsonnet`.
*   **Caching**: Generated manifests are hashed and stored in **Redis**. This prevents the server from re-generating the same YAML for every reconciliation loop.
*   **Isolation**: Each generation happens in a separate temporary directory to ensure one application's logic doesn't interfere with another.

### 3. Application Controller (The Brain)
The Controller is a standard Kubernetes operator that runs the **Reconciliation Loop**.
*   **State Comparison**: It fetches the "Live State" from the Cluster and the "Desired State" from the Repo Server/Redis.
*   **Diffing engine**: It ignores certain fields (like `resourceVersion` or `status`) that are managed by Kubernetes itself, focusing only on the fields you defined in Git.
*   **Action**: If "Auto-Sync" is on, it applies the diff. If not, it simply marks the app as `OutOfSync`.

---

## üîÑ The Reconciliation Loop: Step-by-Step

Argo CD follows a highly optimized 3-step loop:

1.  **Observe**: Every 3 minutes (default `timeout.reconciliation`), the Controller polls the cluster and Git.
    *   *Optimization*: If a **Webhook** is configured from GitHub/GitLab, this 3-minute wait is bypassed, and the loop starts instantly.
2.  **Diff**: The Controller compares thousands of lines of YAML. It identifies "Drift"‚Äîmanual changes made by users that are not in Git.
3.  **Sync**: If a sync is triggered, it follows **Sync Waves** (0, 1, 2...) and **Hooks** (PreSync/PostSync) to ensure dependencies like Database Migrations finish before the application restarts.

---

## üìà Scaling for the Enterprise (Sharding)

When a single Argo CD instance manages 100+ clusters, the Controller can become a bottleneck. Argo CD solves this with **Cluster Sharding**.

*   **How it Works**: You can increase the `replicas` of the `argocd-application-controller`.
*   **Distribution**: Argo CD will automatically distribute the work. Shard 1 might manage clusters A and B, while Shard 2 manages clusters C and D.
*   **Performance**: This spreads the memory and CPU load, ensuring that one slow cluster doesn't delay deployments for the entire company.

---

## üîí Security Architecture: Zero Trust & RBAC

Argo CD is the most privileged tool in your stack, so its internal security is paramount.

*   **Network Posture**: Since it uses a **Pull model**, the cluster needs no inbound ports open. It only initiates outbound HTTPS/SSH connections to Git.
*   **OIDC Flow**: Users log in via your corporate SSO (Okta/AAD). Dex converts that identity into a JWT token that Argo CD understands.
*   **Project Scoping**: Using `AppProject` CRDs, you can "jail" a team. They can be given permission to manage Namespace A, but even if they try to deploy to Namespace B via Git, Argo CD will block it at the controller level.

---

## üèÅ Summary
The architecture of Argo CD is designed to be **Transparent** and **Scalable**. By decoupling the manifest generation (Repo Server) from the state enforcement (Controller), it provides a resilient platform that can grow from a single cluster to thousands of namespaces.
